"""
Test script to verify response-only loss calculation is working correctly.
Standalone test that doesn't require full utils.py dependencies.
"""

import torch
from typing import Tuple


def get_instruct_response_part_mock(tokenizer) -> Tuple[int, int]:
    """Mock version for testing without full dependencies."""
    # These are mock token IDs for testing
    instruction_part = 100  # Mock token ID for instruction boundary
    response_part = 200     # Mock token ID for response boundary
    return instruction_part, response_part


def mask_labels_for_response_only_mock(input_ids: torch.Tensor, labels: torch.Tensor, 
                                      tokenizer, instruction_part: int, response_part: int) -> torch.Tensor:
    """Mock version for testing without full dependencies."""
    # Find where the assistant response starts (mock logic)
    response_start_token_idx = None
    for idx in range(len(input_ids)):
        if input_ids[idx] == instruction_part:
            response_start_token_idx = idx + 1
            break
    
    if response_start_token_idx is None:
        # If we can't find the instruction/response boundary, mask everything
        return torch.full_like(labels, -100)
    
    # Mask everything before the response
    masked_labels = labels.clone()
    masked_labels[:response_start_token_idx] = -100
    
    return masked_labels

def test_response_masking():
    """Test the response-only masking functionality."""
    
    print("="*60)
    print("TESTING RESPONSE-ONLY LOSS MASKING")
    print("="*60)
    
    # Create a mock tokenizer-like object for testing
    class MockTokenizer:
        def decode(self, input_ids, skip_special_tokens=False):
            # Simulate a conversation with user and assistant parts
            return "<|start_header_id|>user<|end_header_id|>\n\nWhat's the weather like?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nThe weather is sunny today.<|eot_id|>"
        
        def encode(self, text, add_special_tokens=False):
            # Simulate tokenization - rough approximation
            words = text.split()
            return list(range(len(words)))  # Mock token IDs
        
        def apply_chat_template(self, conversation, add_generation_prompt=False, tokenize=False):
            if len(conversation) == 3:  # prefix + user message
                return "<|start_header_id|>user<|end_header_id|>\n\nignore<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nignore<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n<user message content>"
            elif len(conversation) == 2:  # just prefix
                return "<|start_header_id|>user<|end_header_id|>\n\nignore<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nignore<|eot_id|>"
            else:
                return ""
    
    tokenizer = MockTokenizer()
    
    # Test getting instruction and response parts
    print("Testing instruction/response part detection...")
    instruction_part, response_part = get_instruct_response_part_mock(tokenizer)
    print(f"Instruction part: '{instruction_part}'")
    print(f"Response part: '{response_part}'")
    
    # Test label masking
    print("\nTesting label masking...")
    
    # Create mock input_ids and labels
    # Simulate: [user tokens] + [instruction_part] + [assistant tokens]
    input_ids = torch.tensor([1, 2, 3, 4, 100, 6, 7, 8, 9, 10, 11, 12])  # 12 tokens total, 100 = instruction_part
    labels = input_ids.clone()
    
    print(f"Original labels: {labels.tolist()}")
    
    # Apply masking
    masked_labels = mask_labels_for_response_only_mock(input_ids, labels, tokenizer, instruction_part, response_part)
    
    print(f"Masked labels: {masked_labels.tolist()}")
    print(f"Masked positions (should be -100): {(masked_labels == -100).sum().item()} out of {len(masked_labels)}")
    
    # Verify that some positions are masked
    if (masked_labels == -100).any():
        print("‚úÖ SUCCESS: Some positions are correctly masked with -100")
    else:
        print("‚ùå WARNING: No positions were masked - this might indicate an issue")
    
    print("\n" + "="*60)
    print("RESPONSE-ONLY MASKING EXPLANATION")
    print("="*60)
    print("In training with train_on_responses_only=True:")
    print("‚úÖ User instructions are masked (label = -100)")
    print("‚úÖ Assistant responses contribute to loss (label = token_id)")
    print("‚úÖ This prevents the model from 'learning' the user questions")
    print("‚úÖ Only assistant responses affect the loss calculation")
    
    return masked_labels

if __name__ == "__main__":
    test_response_masking()
    
    print("\n" + "="*60)
    print("IMPACT ON EXPERIMENT 1")
    print("="*60)
    print("üîÑ Before: Loss calculated on entire sequence (questions + answers)")
    print("üéØ After: Loss calculated only on assistant responses")
    print("üìä Result: More accurate comparison with training setup")
    print("‚öñÔ∏è  Benefit: Fair comparison between different adapters")
    
    print("\nThe loss values will now:")
    print("  - Be lower (only response tokens count)")
    print("  - Be more meaningful (matches training objective)")
    print("  - Enable fairer adapter comparisons")
    print("  - Match the train_on_responses_only=True setting")