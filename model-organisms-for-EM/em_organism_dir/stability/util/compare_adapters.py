#!/usr/bin/env python3
"""
Simple script to compare two adapters with grid search.

Usage examples:
    # Basic comparison with default 5x5 grid
    python compare_adapters.py adapter1 adapter2 questions.yaml
    
    # Custom grid size and loss type
    python compare_adapters.py adapter1 adapter2 questions.yaml --grid-size 7 --loss-type kl
    
    # Custom norm range (25% to 200% of mean)
    python compare_adapters.py adapter1 adapter2 questions.yaml --min-norm 0.25 --max-norm 2.0
"""

import unsloth
import sys
import argparse
# Note: experiment_1_grid_search module doesn't exist in this repo
# from concept_analysis.stability.experiment_1_grid_search import run_grid_search_experiment, create_heatmap_visualization
import json
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def create_comparative_heatmap(results1, results2, output_dir):
    """
    Create a comparative heatmap showing adapter1_loss - adapter2_loss.
    Uses centered scaling where 1.0 represents the mean of original norms.
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # Extract loss grids
    loss_grid1 = np.array(results1['loss_grid'])
    loss_grid2 = np.array(results2['loss_grid'])
    
    # Calculate difference: adapter1 - adapter2
    # Positive values mean adapter1 has higher loss (worse)
    # Negative values mean adapter2 has higher loss (adapter1 is better)
    loss_diff = loss_grid1 - loss_grid2
    
    # Get scale factors and original norms for proper centering
    scale_factors = np.array(results1['scale_factors'])
    adapter1_original_norms = results1['original_norms']
    adapter2_original_norms = results2['original_norms']
    
    # Calculate mean original norms for centering
    mean_a_norm = (adapter1_original_norms['A_norm'] + adapter2_original_norms['A_norm']) / 2
    mean_b_norm = (adapter1_original_norms['B_norm'] + adapter2_original_norms['B_norm']) / 2
    
    # Create figure
    fig, ax = plt.subplots(1, 1, figsize=(12, 10))
    
    # Create heatmap with red-blue colormap
    # Red = adapter1 worse (positive diff), Blue = adapter1 better (negative diff)
    max_abs_diff = np.nanmax(np.abs(loss_diff))
    
    im = ax.imshow(loss_diff, 
                   cmap='RdBu_r',  # Red-Blue reversed (red=positive, blue=negative)
                   aspect='auto', 
                   origin='lower',
                   vmin=-max_abs_diff, 
                   vmax=max_abs_diff)
    
    # Add colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Loss Difference (Adapter1 - Adapter2)', rotation=270, labelpad=20)
    
    # Set ticks and labels with scale factors
    ax.set_xticks(range(len(scale_factors)))
    ax.set_yticks(range(len(scale_factors)))
    ax.set_xticklabels([f'{s:.2f}' for s in scale_factors])
    ax.set_yticklabels([f'{s:.2f}' for s in scale_factors])
    
    # Add difference values as text
    for i in range(len(scale_factors)):
        for j in range(len(scale_factors)):
            if not np.isnan(loss_diff[i, j]):
                # Choose text color based on background
                text_color = 'white' if abs(loss_diff[i, j]) > max_abs_diff * 0.5 else 'black'
                text = ax.text(j, i, f'{loss_diff[i, j]:.3f}', 
                              ha="center", va="center", 
                              color=text_color, fontsize=8, weight='bold')
    
    # Mark the center point (1.0, 1.0) - original norms
    center_idx = len(scale_factors) // 2
    ax.plot(center_idx, center_idx, 'ko', markersize=12, markerfacecolor='yellow', 
            markeredgecolor='black', markeredgewidth=2, alpha=0.8)
    ax.text(center_idx, center_idx + 0.3, 'Original\nNorms', 
            ha='center', va='bottom', fontsize=10, weight='bold',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
    
    # Labels and title
    ax.set_xlabel('B Matrix Scale Factor')
    ax.set_ylabel('A Matrix Scale Factor')
    
    adapter1_name = os.path.basename(results1['adapter_path'])
    adapter2_name = os.path.basename(results2['adapter_path'])
    ax.set_title(f'Loss Difference Comparison\n{adapter1_name}\nvs\n{adapter2_name}\n'
                f'(Red: Adapter1 worse, Blue: Adapter1 better)', fontsize=14)
    
    # Add norm information
    textstr = f'Original Norms (Mean):\nA: {mean_a_norm:.4f}\nB: {mean_b_norm:.4f}'
    props = dict(boxstyle='round', facecolor='lightgray', alpha=0.8)
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=props)
    
    # Add legend for color interpretation
    legend_text = ('Red: Adapter1 has higher loss (worse performance)\n'
                  'Blue: Adapter1 has lower loss (better performance)\n'
                  'White: Similar performance')
    ax.text(0.98, 0.02, legend_text, transform=ax.transAxes, fontsize=10,
            verticalalignment='bottom', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    plt.tight_layout()
    
    # Save plot
    plot_path = os.path.join(output_dir, 'loss_difference_comparison.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"📊 Comparative heatmap saved to: {plot_path}")
    
    plt.show()
    
    # Print summary statistics
    print("\n📈 Comparison Summary:")
    valid_diffs = loss_diff[~np.isnan(loss_diff)]
    if len(valid_diffs) > 0:
        print(f"  Mean difference: {np.mean(valid_diffs):.4f}")
        print(f"  Std difference: {np.std(valid_diffs):.4f}")
        print(f"  Min difference: {np.min(valid_diffs):.4f} (max advantage to Adapter1)")
        print(f"  Max difference: {np.max(valid_diffs):.4f} (max advantage to Adapter2)")
        
        adapter1_better = np.sum(valid_diffs < 0)
        adapter2_better = np.sum(valid_diffs > 0)
        similar = np.sum(np.abs(valid_diffs) < 0.001)
        
        print(f"  Adapter1 better: {adapter1_better}/{len(valid_diffs)} points ({adapter1_better/len(valid_diffs)*100:.1f}%)")
        print(f"  Adapter2 better: {adapter2_better}/{len(valid_diffs)} points ({adapter2_better/len(valid_diffs)*100:.1f}%)")
        print(f"  Similar performance: {similar}/{len(valid_diffs)} points ({similar/len(valid_diffs)*100:.1f}%)")

def main():
    parser = argparse.ArgumentParser(
        description='Compare two LoRA adapters across different norm scalings',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic 5x5 comparison with SFT loss
  python compare_adapters.py model1 model2 questions.yaml
  
  # 7x7 grid with KL divergence
  python compare_adapters.py model1 model2 questions.yaml --grid-size 7 --loss-type kl
  
  # Custom norm range (25% to 200%)
  python compare_adapters.py model1 model2 questions.yaml --min-norm 0.25 --max-norm 2.0
        """
    )
    
    parser.add_argument('adapter1', help='First LoRA adapter path')
    parser.add_argument('adapter2', help='Second LoRA adapter path') 
    parser.add_argument('questions', help='Questions dataset path')
    parser.add_argument('--grid-size', type=int, default=5, help='Grid size (default: 5x5)')
    parser.add_argument('--min-norm', type=float, default=0.5, help='Min norm factor (default: 0.5 = 50%%)')
    parser.add_argument('--max-norm', type=float, default=1.5, help='Max norm factor (default: 1.5 = 150%%)')
    parser.add_argument('--loss-type', choices=['sft', 'kl'], default='sft', help='Loss type (default: sft)')
    parser.add_argument('--max-samples', type=int, default=50, help='Max samples (default: 50)')
    parser.add_argument('--seed', type=int, default=42, help='Random seed (default: 42)')
    parser.add_argument('--output-name', help='Custom output name (auto-generated if not provided)')
    
    args = parser.parse_args()
    
    # Auto-generate output name if not provided
    if args.output_name:
        output_base = args.output_name
    else:
        adapter1_name = os.path.basename(args.adapter1).replace('/', '_')
        adapter2_name = os.path.basename(args.adapter2).replace('/', '_')
        questions_name = os.path.basename(args.questions).replace('.yaml', '').replace('.jsonl', '')
        output_base = f"comparison_{adapter1_name}_vs_{adapter2_name}_{questions_name}_{args.loss_type}_{args.grid_size}x{args.grid_size}"
    
    output_json = f"{output_base}.json"
    output_dir = f"{output_base}_plots"
    
    print(f"🔍 Comparing: {args.adapter1} vs {args.adapter2}")
    print(f"📊 Grid: {args.grid_size}x{args.grid_size}, Norms: {args.min_norm*100:.0f}%-{args.max_norm*100:.0f}%")
    print(f"📝 Loss: {args.loss_type}, Samples: {args.max_samples}")
    print(f"💾 Output: {output_json}, {output_dir}/")
    
    # Run grid search for each adapter
    print("\n🔄 Running grid search for adapter 1...")
    results1 = run_grid_search_experiment(
        adapter_path=args.adapter1,
        test_dataset_path=args.questions,
        grid_size=args.grid_size,
        scale_range=(args.min_norm, args.max_norm),
        max_samples=args.max_samples,
        seed=args.seed
    )
    
    print("\n🔄 Running grid search for adapter 2...")
    results2 = run_grid_search_experiment(
        adapter_path=args.adapter2,
        test_dataset_path=args.questions,
        grid_size=args.grid_size,
        scale_range=(args.min_norm, args.max_norm),
        max_samples=args.max_samples,
        seed=args.seed
    )
    
    # Combine results for comparison
    results = {
        'adapter1': results1,
        'adapter2': results2,
        'comparison_metadata': {
            'adapter1_path': args.adapter1,
            'adapter2_path': args.adapter2,
            'questions_path': args.questions,
            'grid_size': args.grid_size,
            'scale_range': (args.min_norm, args.max_norm),
            'max_samples': args.max_samples,
            'seed': args.seed
        }
    }
    
    # Save results
    with open(output_json, 'w') as f:
        json.dump(results, f, indent=2)
    
    # Create plots for each adapter
    print("\n🎨 Creating visualization plots...")
    adapter1_plot_dir = f"{output_dir}/adapter1"
    adapter2_plot_dir = f"{output_dir}/adapter2"
    comparison_plot_dir = f"{output_dir}/comparison"
    
    create_heatmap_visualization(results1, adapter1_plot_dir)
    create_heatmap_visualization(results2, adapter2_plot_dir)
    
    # Create comparative difference heatmap
    print("\n🔥 Creating comparative difference heatmap...")
    create_comparative_heatmap(results1, results2, comparison_plot_dir)
    
    print(f"\n✅ Comparison complete!")
    print(f"📁 Results: {output_json}")
    print(f"🖼️  Plots: {output_dir}/")

if __name__ == "__main__":
    main()